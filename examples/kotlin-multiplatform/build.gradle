import org.jetbrains.kotlin.konan.target.HostManager
import org.jetbrains.kotlin.konan.target.KonanTarget
import kotlinx.benchmark.gradle.JsBenchmarksExecutor

plugins {
    id 'org.jetbrains.kotlin.multiplatform'
    id 'org.jetbrains.kotlin.plugin.allopen' version "1.9.0"
    id 'org.jetbrains.kotlinx.benchmark'
}

// how to apply plugin to a specific source set?
allOpen {
    annotation("org.openjdk.jmh.annotations.State")
}

def distinguishAttribute = Attribute.of('kotlinx-benchmark-distinguishAttribute', String)

kotlin {
    jvm {
        compilations.create('benchmark') { associateWith(compilations.main) }
    }
    js('jsIr', IR) {
        nodejs()
        attributes.attribute(distinguishAttribute, 'jsIr')
    }
    js('jsIrBuiltIn', IR) {
        nodejs()
        attributes.attribute(distinguishAttribute, 'jsIrBuiltIn')
    }
    wasm('wasmJs') { d8() }
    if (HostManager.host == KonanTarget.MACOS_X64.INSTANCE) macosX64('native')
    if (HostManager.host == KonanTarget.MACOS_ARM64.INSTANCE) macosArm64('native')
    if (HostManager.hostIsLinux) linuxX64('native')
    if (HostManager.hostIsMingw) mingwX64('native')

    sourceSets.all {
        languageSettings {
            progressiveMode = true
        }
    }

    sourceSets {
        commonMain {
            dependencies {
                implementation project(":kotlinx-benchmark-runtime")
            }
        }

        jvmMain {}

        wasmJsMain {}

        jsMain {
            jsIrMain.dependsOn(it)
            jsIrBuiltInMain.dependsOn(it)
        }

        nativeMain {
            dependsOn(commonMain)
        }
    }
}

// Configure benchmark
benchmark {
    configurations {
        main { // --> jvmBenchmark, jsBenchmark, <native target>Benchmark, benchmark
            iterations = 5 // number of iterations
            iterationTime = 300
            iterationTimeUnit = "ms"
            advanced("jvmForks", 3)
            advanced("jsUseBridge", true)
        }

        params {
            iterations = 5 // number of iterations
            iterationTime = 300
            iterationTimeUnit = "ms"
            include("ParamBenchmark")
            param("data", 5, 1, 8)
            param("unused", 6, 9)
        }

        fast { // --> jvmFastBenchmark, jsFastBenchmark, <native target>FastBenchmark, fastBenchmark
            include("Common")
            exclude("long")
            iterations = 5
            iterationTime = 300 // time in ms per iteration
            iterationTimeUnit = "ms" // time in ms per iteration
            advanced("nativeGCAfterIteration", true)
        }

        csv {
            include("Common")
            exclude("long")
            iterations = 1
            iterationTime = 300
            iterationTimeUnit = "ms"
            reportFormat = "csv" // csv report format
        }

        fork {
            include("CommonBenchmark")
            iterations = 5
            iterationTime = 300
            iterationTimeUnit = "ms"
            advanced("jvmForks", "definedByJmh") // see README.md for possible "jvmForks" values
            advanced("nativeFork", "perIteration") // see README.md for possible "nativeFork" values
        }
    }

    // Setup configurations
    targets {
        // This one matches target name, e.g. 'jvm', 'js',
        // and registers its 'main' compilation, so 'jvm' registers 'jvmMain'
        register("jvm") {
            jmhVersion = "1.21"
        }
        // This one matches source set name, e.g. 'jvmMain', 'jvmTest', etc
        // and register the corresponding compilation (here the 'benchmark' compilation declared in the 'jvm' target)
        register("jvmBenchmark") {
            jmhVersion = "1.21"
        }
        register("jsIr")
        register("jsIrBuiltIn") {
            jsBenchmarksExecutor = JsBenchmarksExecutor.BuiltIn
        }
        register("wasmJs")
        register("native")
    }
}